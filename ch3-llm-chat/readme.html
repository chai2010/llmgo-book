<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using https://github.com/wa-lang/wabook -->
        <meta charset="UTF-8">
        <title>LLM聊天机器人 - Go和大语言模型编程</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../static/wabook/css/variables.css">
        <link rel="stylesheet" href="../static/wabook/css/general.css">
        <link rel="stylesheet" href="../static/wabook/css/chrome.css">
        <link rel="stylesheet" href="../static/wabook/css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../static/wabook/FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../static/wabook/fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../static/wabook/highlight.css">
        <link rel="stylesheet" href="../static/wabook/tomorrow-night.css">
        <link rel="stylesheet" href="../static/wabook/ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('wabook-theme');
                var sidebar = localStorage.getItem('wabook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('wabook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('wabook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('wabook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('wabook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter">
  <li class="chapter-item expanded ">
    <a href="../index.html" >Go和大语言模型编程</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../preface.html" >前言</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch1-hello-llm/readme.html" ><strong aria-hidden="true">1.</strong> 你好，Ollama</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch2-rest-api/readme.html" ><strong aria-hidden="true">2.</strong> 访问REST服务</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch3-llm-chat/readme.html" class="active"><strong aria-hidden="true">3.</strong> LLM聊天机器人</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch4-modelfile/readme.html" ><strong aria-hidden="true">4.</strong> 大模型文件结构</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch5-loadmodel/readme.html" ><strong aria-hidden="true">5.</strong> 手动加载模型文件</a>
  </li>
</ol>

            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title"><a href="../index.html">Go和大语言模型编程</a></h1>

                    <div class="right-buttons">
                        <a href="https://github.com/chai2010/llmgo-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/chai2010/llmgo-book/edit/master/ch3-llm-chat/readme.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <!-- Page table of contents -->
                    <div class="sidetoc"><nav class="pagetoc"></nav></div>

                    <main>
                        

                        <h1>3. LLM聊天机器人</h1>
<p>LangChain是专门用于开发LLM驱动型应用程序的框架，而LangChain Go是LangChain框架的Go语言实现。现在我们尝试用LangChain Go连接Ollama运行的本地大模型，然后构建一个LLM聊天机器人。</p>
<h2>3.1 连接Ollama</h2>
<p>通过LangChainGo连接Ollama非常简单：</p>
<pre><code class="language-go">package main

import (
	&quot;context&quot;
	&quot;fmt&quot;

	&quot;github.com/tmc/langchaingo/llms&quot;
	&quot;github.com/tmc/langchaingo/llms/ollama&quot;
)

func main() {
	llm, _ := ollama.New(ollama.WithModel(&quot;deepseek-r1:1.5b&quot;))
	completion, _ := llms.GenerateFromSinglePrompt(
		context.Background(), llm, &quot;hello deepseek&quot;,
	)
	fmt.Println(completion)
}
</code></pre>
<p>本地执行结果如下：</p>
<pre><code>$ go run .
&lt;think&gt;

&lt;/think&gt;

Hello! How can I assist you today? 😊
</code></pre>
<h2>3.2 命令行聊天程序</h2>
<p>先构造一个命令行环境的聊天程序，每次对话不包含上下文信息。首先包装一个<code>LLMChat</code>函数：</p>
<pre><code class="language-go">func LLMChat(prompt string) (string, error) {
	llm, err := ollama.New(ollama.WithModel(&quot;deepseek-r1:1.5b&quot;))
	if err != nil {
		return &quot;&quot;, err
	}

	return llms.GenerateFromSinglePrompt(context.Background(), llm, prompt)
}
</code></pre>
<p>然后再main函数中以交互的方式调用<code>LLMChat</code>函数：</p>
<pre><code class="language-go">func main() {
	// 提示用户
	fmt.Println(&quot;请输入聊天对话内容，输入 '/bye' 退出。&quot;)

	// 循环读取输入
	scanner := bufio.NewScanner(os.Stdin)
	for {
		// 提示用户输入
		fmt.Print(&quot;&gt;&gt; &quot;)

		// 读取一行输入
		scanner.Scan()
		input := scanner.Text()

		// 如果输入的是 '/bye'，退出循环
		if strings.ToLower(input) == &quot;/bye&quot; {
			break
		}

		response, err := LLMChat(input)
		if err != nil {
			fmt.Printf(&quot;ERROR: %v\n&quot;, err)
			continue
		}
		fmt.Println(response)
	}
}
</code></pre>
<p>执行的效果如下：</p>
<pre><code>$ go run .
请输入聊天对话内容，输入 '/bye' 退出。
&gt;&gt; hello deepseek
&lt;think&gt;

&lt;/think&gt;

Hello! How can I assist you today? 😊
&gt;&gt; /bye
$
</code></pre>
<h2>3.3 Web聊天程序</h2>
<p>现在构建Web版本的聊天程序。先定义服务对象和公开的方法：</p>
<pre><code class="language-go">type Option struct {
	Model string
}

type LLMChatServer struct {
	fs  fs.FS
	opt Option
}

func NewLLMChatServer(opt Option) *LLMChatServer {}
func (p *LLMChatServer) Run(addr string) error {}
</code></pre>
<p><code>Option</code>是基本的配置参数，<code>LLMChatServer</code>是聊天服务对象，然后有个<code>LLMChatServer.Run()</code>启动服务。</p>
<p>然后在<code>main</code>函数可以调用以上的服务：</p>
<pre><code class="language-go">func main() {
	s := NewLLMChatServer(Option{
		Model: &quot;deepseek-r1:1.5b&quot;,
	})
	s.Run(&quot;localhost:8080&quot;)
}
</code></pre>
<p>然后在<code>http://localhost:8080</code>地址启动聊天服务。现在可以继续实现<code>NewLLMChatServer</code>构造函数：</p>
<pre><code class="language-go">//go:embed static
var embedStaticFS embed.FS

func NewLLMChatServer(opt Option) *LLMChatServer {
	fs, err := fs.Sub(embedStaticFS, &quot;static&quot;)
	if err != nil {
		panic(err)
	}
	p := &amp;LLMChatServer{fs: fs, opt: opt}
	return p
}
</code></pre>
<p>首先是嵌入<code>static</code>目录，其中包含聊天的前端资源。然后完善<code>Option</code>缺少的参数，最后构建<code>LLMChatServer</code>对象返回。</p>
<p>接着是实现<code>LLMChatServer.Run()</code>方法：</p>
<pre><code class="language-go">func (p *LLMChatServer) Run(addr string) error {
	fmt.Println(&quot;listen on http://&quot; + addr)
	startTime := time.Now()
	return http.ListenAndServe(addr,
		http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			fmt.Println(r.Method, r.URL.Path)

			switch {
			case r.URL.Path == &quot;/&quot;:
				p.indexHandler(w, r)
			case r.URL.Path == &quot;/run&quot;:
				p.runHandler(w, r)
			case strings.HasPrefix(r.URL.Path, &quot;/static/&quot;):
				relpath := strings.TrimPrefix(r.URL.Path, &quot;/static/&quot;)
				data, err := fs.ReadFile(p.fs, relpath)
				if err != nil {
					http.NotFound(w, r)
					return
				}

				http.ServeContent(w, r, r.URL.Path, startTime, bytes.NewReader(data))

			default:
				http.NotFound(w, r)
			}
		}),
	)
}
</code></pre>
<p>注意是通过<code>http.ListenAndServe()</code>设置理由处理函数并启动服务。其中“/”路径对应聊天主页面的处理<code>p.indexHandler(w, r)</code>，“/run”提供和大模型聊天的REST接口<code>p.runHandler(w, r)</code>，“/static/*”则是静态文件。</p>
<p>聊天主页面的处理逻辑比较简单，就是将<code>static/index.html</code>资源的内容返回：</p>
<pre><code class="language-go">func (p *LLMChatServer) indexHandler(w http.ResponseWriter, r *http.Request) {
	data, err := fs.ReadFile(p.fs, &quot;index.html&quot;)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	w.Write(data)
}
</code></pre>
<p>然后是<code>/run</code>接口的实现：</p>
<pre><code class="language-go">func (p *LLMChatServer) runHandler(w http.ResponseWriter, r *http.Request) {
	prompt := struct {
		Input string `json:&quot;input&quot;`
	}{}
	err := json.NewDecoder(r.Body).Decode(&amp;prompt)
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	resp, err := LLMChat(prompt.Input)
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	json.NewEncoder(w).Encode(map[string]string{
		&quot;input&quot;:    prompt.Input,
		&quot;response&quot;: resp,
	})
}
</code></pre>
<p>通过接收客户端发送来的JSON数据，解析出其中的“input”字段作为聊天的内存，然后调用<code>LLMChat(prompt.Input)</code>获取大模型返回的内存，最终再以JSON格式编码并返回。</p>
<p>现在执行服务后用浏览器打开的效果如图：</p>
<p><img src="./images/ch3.3-chat.png" alt=""></p>
<h2>3.4 多轮对话</h2>
<p>通过<code>llm.GenerateContent()</code>函数可以传入多轮对话的上下文：</p>
<pre><code class="language-go">func main() {
	llm, err := ollama.New(ollama.WithModel(&quot;deepseek-r1:1.5b&quot;))
	if err != nil {
		panic(err)
	}

	requestContent := []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeHuman, &quot;你好，今天怎么样？&quot;),
		llms.TextParts(llms.ChatMessageTypeSystem, &quot;你好呀！我今天很好，谢谢！&quot;),
		llms.TextParts(llms.ChatMessageTypeHuman, &quot;你做了什么？&quot;),
		llms.TextParts(llms.ChatMessageTypeSystem, &quot;我今天一直在和你聊天！&quot;),
		llms.TextParts(llms.ChatMessageTypeHuman, &quot;那我们继续聊吧！&quot;),
	}

	completion, err := llm.GenerateContent(context.Background(), requestContent)
	if err != nil {
		panic(err)
	}
	if len(completion.Choices) == 0 {
		panic(&quot;no response&quot;)
	}

	fmt.Println(completion.Choices[0].Content)
}
</code></pre>
<p>执行效果如下：</p>
<pre><code>$ go run .
&lt;think&gt;
...
&lt;/think&gt;

你好呀！今天确实过得很好，谢谢你的关心！你最近一直在和我聊天吗？有什么特别的事情想分享吗？
</code></pre>
<p>其中<code>&lt;think&gt;</code>和<code>&lt;/think&gt;</code>之间标注的思考过程如下：</p>
<blockquote>
<p>嗯，用户一开始说“你好呀！我今天很好，谢谢！”然后回复了“我今天一直在和你聊天！”看起来是在确认之前的对话。接着，用户又问：“你做了什么？”这可能是在测试我的反应是否正常。</p>
<p>接下来，我回复了“你好，今天怎么样？”，这是一个友好的回应，让用户感到被重视。然后，我继续说：“那我们继续聊吧！”这样引导用户继续互动，保持对话的持续性。</p>
<p>用户最后回复的是“那我们继续聊吧！”，这表明他们已经同意我的建议，并希望进一步交流。可能用户觉得之前的回复不够友好，或者想确认是否真的在聊天，所以再次确认了话题。</p>
<p>总的来说，用户的对话主要是在确认和对方的聊天情况，同时保持友好的互动。我需要确保回应既友好又积极，让用户感到被支持。</p>
</blockquote>
<p>简单来说，多轮对话会让大模型以深度思考模式工作。这里就不展示集成到Web聊天程序的细节了。</p>
<h2>3.5 二进制文件</h2>
<p>也可以通过<code>llms.BinaryPart()</code>函数传入二进制数据。比如希望让大模型描述以下图片：</p>
<p><img src="./images/ch3.4-llama.png" alt=""></p>
<p>传入大模型的请求数据如下：</p>
<pre><code class="language-go">//go:embed llama.png
var llamaImageData []byte

func main() {
	...
	requestContent := []llms.MessageContent{
		llms.MessageContent{
			Role: llms.ChatMessageTypeHuman,
			Parts: []llms.ContentPart{
				llms.BinaryPart(&quot;image/png&quot;, llamaImageData),
			},
		},
		llms.MessageContent{
			Role: llms.ChatMessageTypeHuman,
			Parts: []llms.ContentPart{
				llms.TextContent{Text: &quot;What's in this image?&quot;},
			},
		},
	}
	...
}
</code></pre>
<p>执行输出如下：</p>
<pre><code>$ go run main.go 
I'm unable to view or process images directly. However, if you can describe
the image to me, I’d be happy to help analyze and answer your questions!
</code></pre>
<p>虽然我们本地测试的小模型还不能很好地理解图片，但是API的工作方式是类似的。</p>


                        

                        

                        
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../ch2-rest-api/readme.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                        
                            <!-- ../ch4-modelfile/readme.html -->
                            <a rel="next" href="../ch4-modelfile/readme.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../ch2-rest-api/readme.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                
                    <a rel="next" href="../ch4-modelfile/readme.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../static/wabook/mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/book.js" type="text/javascript" charset="utf-8"></script>
        
        <script type="text/javascript" charset="utf-8">
            var pagePath = "ch3-llm-chat/readme.md"
        </script>

        <!-- Custom JS scripts -->
        

    </body>
</html>
