<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using https://github.com/wa-lang/wabook -->
        <meta charset="UTF-8">
        <title>访问REST服务 - Go和大语言模型编程</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../static/wabook/css/variables.css">
        <link rel="stylesheet" href="../static/wabook/css/general.css">
        <link rel="stylesheet" href="../static/wabook/css/chrome.css">
        <link rel="stylesheet" href="../static/wabook/css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../static/wabook/FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../static/wabook/fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../static/wabook/highlight.css">
        <link rel="stylesheet" href="../static/wabook/tomorrow-night.css">
        <link rel="stylesheet" href="../static/wabook/ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('wabook-theme');
                var sidebar = localStorage.getItem('wabook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('wabook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('wabook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('wabook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('wabook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter">
  <li class="chapter-item expanded ">
    <a href="../index.html" >Go和大语言模型编程</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../preface.html" >前言</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch1-hello-llm/readme.html" ><strong aria-hidden="true">1.</strong> 你好，Ollama</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch2-rest-api/readme.html" class="active"><strong aria-hidden="true">2.</strong> 访问REST服务</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch3-llm-chat/readme.html" ><strong aria-hidden="true">3.</strong> LLM聊天机器人</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch4-modelfile/readme.html" ><strong aria-hidden="true">4.</strong> 大模型文件结构</a>
  </li>
  <li class="chapter-item expanded ">
    <a href="../ch5-loadmodel/readme.html" ><strong aria-hidden="true">5.</strong> 手动加载模型文件</a>
  </li>
</ol>

            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title"><a href="../index.html">Go和大语言模型编程</a></h1>

                    <div class="right-buttons">
                        <a href="https://github.com/chai2010/llmgo-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/chai2010/llmgo-book/edit/master/ch2-rest-api/readme.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <!-- Page table of contents -->
                    <div class="sidetoc"><nav class="pagetoc"></nav></div>

                    <main>
                        

                        <h1>2. 访问REST服务</h1>
<p>因为执行完整版的大语言模型通常需要大量的硬件资源，因此大语言模型一般会以服务的形式运行在特殊的硬件上，然后通过REST协议提高服务。本书的目的不是为了学习REST协议，但是通过他可以了解大语言模型对外提供服务的方式，达到一定的去魅的目的。</p>
<h2>2.1 查看模型列表</h2>
<p>Ollama不仅仅是命令，他一般是以一个独立的应用安装，安装后打开就默认在11434端口启动了服务。比如<code>/api/tags</code>接口可以返回当前安装的模型（和<code>ollama list</code>命令类似）：</p>
<pre><code>$ curl http://localhost:11434/api/tags
{&quot;models&quot;:[{&quot;name&quot;:&quot;deepseek-r1:1.5b&quot;,&quot;model&quot;:&quot;deepseek-r1:1.5b&quot;, ...
</code></pre>
<p>REST服务返回的是JSON格式的数据，格式化后完整的数据如下：</p>
<pre><code class="language-json">{
  &quot;models&quot;: [
    {
      &quot;name&quot;:&quot;deepseek-r1:1.5b&quot;,
      &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
      &quot;modified_at&quot;:&quot;2025-02-09T16:23:27.221768541+08:00&quot;,
      &quot;size&quot;:1117322599,
      &quot;digest&quot;:&quot;a42b25d8c10a841bd24724309898ae851466696a7d7f3a0a408b895538ccbc96&quot;,
      &quot;details&quot;: {
        &quot;parent_model&quot;:&quot;&quot;,
        &quot;format&quot;:&quot;gguf&quot;,
        &quot;family&quot;:&quot;qwen2&quot;,
        &quot;families&quot;:[&quot;qwen2&quot;],
        &quot;parameter_size&quot;:&quot;1.8B&quot;,
        &quot;quantization_level&quot;:&quot;Q4_K_M&quot;
      }
    }
  ]
}
</code></pre>
<h2>2.2 通过API和大模型聊天</h2>
<p>如果想和大模型聊天，可以采用OpenAI风格的REST接口。创建request.json文件如下：</p>
<pre><code class="language-json">{
  &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请帮我写一封邮件给老板，告诉他我明天不能来上班。&quot;}
  ],
  &quot;temperature&quot;: 0.7,
  &quot;max_tokens&quot;: 150
}
</code></pre>
<p>指定<code>deepseek-r1:1.5b</code>大模型，然后以<code>user</code>角色发出对话内容，其他参数可以忽略。然后通过curl发出请求：</p>
<pre><code>$ curl -X POST http://localhost:11434/v1/chat/completions \
       -H &quot;Content-Type: application/json&quot; \
       -d @request.json
</code></pre>
<p>POST请求的API地址为<code>/v1/chat/completions</code>，通过<code>-H</code>指定请求文件为JSON格式，通过<code>-d</code>参数指定JSON文件数据。执行的结果如下：</p>
<pre><code class="language-json">{
  &quot;id&quot;:&quot;chatcmpl-201&quot;,
  &quot;object&quot;:&quot;chat.completion&quot;,
  &quot;created&quot;:1740558137,
  &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
  &quot;system_fingerprint&quot;:&quot;fp_ollama&quot;,
  &quot;choices&quot;:[
    {
      &quot;index&quot;:0,
      &quot;message&quot;:{
        &quot;role&quot;:&quot;assistant&quot;,
        &quot;content&quot;:&quot;...回答的内容...&quot;
      },
      &quot;finish_reason&quot;:&quot;length&quot;
    }
  ],
  &quot;usage&quot;:{
    &quot;prompt_tokens&quot;:18,
    &quot;completion_tokens&quot;:150,
    &quot;total_tokens&quot;:168
  }
}
</code></pre>
<p>完整的回答内容如下：</p>
<blockquote>
<p>嗯，用户让我帮他写一封给他老板的邮件，告诉他他明天不能来上班。首先，我得想想用户的具体情况。可能是一个刚入职的人，但因为某些原因无法按时到岗，或者有其他安排，导致需要提前通知老板。</p>
<p>接下来，我要考虑邮件的结构。通常来说，正式的商务邮件包括称呼、开头问候、说明理由、表达歉意和感谢、并留下联系方式等部分。这样看起来更专业，也更有礼貌。</p>
<p>用户可能没有提到具体的原因，所以我的回应中应该留有 blanks，让他能填写具体情况。比如，是否因为家庭问题无法到岗，还是其他临时原因？这样可以让他知道邮件可以根据实际情况调整内容。</p>
<p>另外，语气</p>
</blockquote>
<p>OpenAI的REST接口风格已经成为事实上的标准，通过类似的方式不仅仅可以连接OpenAI服务，甚至也可以连接DeepSeek提供的服务。</p>
<h2>2.3 聊天的上下文</h2>
<p>要通过<code>curl</code>实现多轮聊天，你需要在每次请求时将之前的对话历史（即消息）传递给模型，以便模型能够基于上下文生成合理的回答。<code>ollama</code> 的 API 会将整个对话历史作为请求的一部分，以便生成基于上下文的响应。</p>
<p>在每次与模型对话时，你将之前的用户和助手消息一并发送给 API，这样模型就能理解对话的上下文。假设你已经启动了 <code>ollama</code> 的 API，并且模型在 <code>localhost:11434</code> 上运行。以下是一个多轮聊天的示例。</p>
<h3>2.3.1 第一次对话</h3>
<p>在第一次发送请求时，你的 <code>request.json</code> 文件可能是这样的：</p>
<pre><code class="language-json">{
  &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，今天怎么样？&quot;}
  ]
}
</code></pre>
<p>第一次请求时，我们会发送一个用户的消息：</p>
<pre><code class="language-bash">$ curl -X POST http://localhost:11434/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d @request.json
</code></pre>
<p>假设模型的回应如下：</p>
<pre><code class="language-json">{
  &quot;id&quot;:&quot;chatcmpl-507&quot;,
  &quot;object&quot;:&quot;chat.completion&quot;,
  &quot;created&quot;:1740572517,
  &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
  &quot;system_fingerprint&quot;:&quot;fp_ollama&quot;,
  &quot;choices&quot;:[
    {
      &quot;index&quot;:0,
      &quot;message&quot;:{
        &quot;role&quot;:&quot;assistant&quot;,
        &quot;content&quot;:&quot;您好！感觉怎么样呢？如果您有任何问题或需要帮助的地方，请随时告诉我。我会尽力为您提供更好的服务。&quot;
      },
      &quot;finish_reason&quot;:&quot;stop&quot;
    }
  ],
  &quot;usage&quot;:{
    &quot;prompt_tokens&quot;:8,
    &quot;completion_tokens&quot;:28,
    &quot;total_tokens&quot;:36
  }
}
</code></pre>
<h3>2.3.2 进行第二轮对话</h3>
<p>在第二轮对话中，你需要将用户的消息和模型的回应一并添加到 <code>messages</code> 数组中。例如，用户接着问：“你做了什么？”：</p>
<p>更新后的 <code>request.json</code> 文件：</p>
<pre><code class="language-json">{
  &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，今天怎么样？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;您好！感觉怎么样呢？如果您有任何问题或需要帮助的地方，请随时告诉我。我会尽力为您提供更好的服务。！&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你做了什么？&quot;}
  ]
}
</code></pre>
<p>然后，发送第二轮请求：</p>
<pre><code class="language-bash">$ curl -X POST http://localhost:11434/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d @request.json
</code></pre>
<p>模型将基于所有历史消息（包括助手的回应）来生成回答。例如，模型可能会回应：</p>
<pre><code class="language-json">{
  &quot;id&quot;:&quot;chatcmpl-208&quot;,
  &quot;object&quot;:&quot;chat.completion&quot;,
  &quot;created&quot;:1740572681,
  &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
  &quot;system_fingerprint&quot;:&quot;fp_ollama&quot;,
  &quot;choices&quot;:[
    {
      &quot;index&quot;:0,
      &quot;message&quot;:{
        &quot;role&quot;:&quot;assistant&quot;,
        &quot;content&quot;:&quot;好的，现在我们可以先专注于当前的问题和相关回复。如果还有其他问题需要我帮忙解答的，请随时告诉我。我们共同进步，一起成长！&quot;
      },
      &quot;finish_reason&quot;:&quot;stop&quot;
    }
  ],
  &quot;usage&quot;:{
    &quot;prompt_tokens&quot;:39,
    &quot;completion_tokens&quot;:37,
    &quot;total_tokens&quot;:76
  }
}
</code></pre>
<h3>2.3.3 第三轮对话</h3>
<p>如果用户继续提问，可以像之前一样更新 <code>request.json</code> 文件，逐步将对话历史传递给模型。更新后的 <code>request.json</code> 文件（第三轮对话）：</p>
<pre><code class="language-json">{
  &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，今天怎么样？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;您好！感觉怎么样呢？如果您有任何问题或需要帮助的地方，请随时告诉我。我会尽力为您提供更好的服务。！&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你做了什么？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;好的，现在我们可以先专注于当前的问题和相关回复。如果还有其他问题需要我帮忙解答的，请随时告诉我。我们共同进步，一起成长！&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;那我们继续聊吧！&quot;}
  ]
}
</code></pre>
<p>然后再发送：</p>
<pre><code class="language-bash">$ curl -X POST http://localhost:11434/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d @request.json
</code></pre>
<p>返回的结果如下：</p>
<pre><code class="language-json">{
  &quot;id&quot;:&quot;chatcmpl-134&quot;,
  &quot;object&quot;:&quot;chat.completion&quot;,
  &quot;created&quot;:1740573171,
  &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
  &quot;system_fingerprint&quot;:&quot;fp_ollama&quot;,
  &quot;choices&quot;:[
    {
      &quot;index&quot;:0,
      &quot;message&quot;:{
        &quot;role&quot;:&quot;assistant&quot;,
        &quot;content&quot;:&quot;您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。有关模型和产品的详细内容请参考官方文档。&quot;
      },
      &quot;finish_reason&quot;:&quot;stop&quot;
    }
  ],
  &quot;usage&quot;:{
    &quot;prompt_tokens&quot;:80,
    &quot;completion_tokens&quot;:38,
    &quot;total_tokens&quot;:118
  }
}
</code></pre>
<h2>2.4 上下文校准</h2>
<p>因为采用的是DeepSeek小模型测试，回答的效果并不太好，读者可以自行更换为更大的模型测试。不过在在进行多轮对话中，我们也可以调整或构建新的对话上下文。比如我们之间以下面的数据进入另一个版本的对话中：</p>
<pre><code class="language-json">{
  &quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
  &quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，今天怎么样？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;你好呀！我今天很好，谢谢！&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你做了什么？&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;我今天一直在和你聊天！&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;那我们继续聊吧！&quot;}
  ],
  &quot;temperature&quot;: 0.7,
  &quot;max_tokens&quot;: 150
}
</code></pre>
<p>重新请求后返回的结果如下：</p>
<pre><code class="language-json">{
  &quot;id&quot;:&quot;chatcmpl-891&quot;,
  &quot;object&quot;:&quot;chat.completion&quot;,
  &quot;created&quot;:1740573640,
  &quot;model&quot;:&quot;deepseek-r1:1.5b&quot;,
  &quot;system_fingerprint&quot;:&quot;fp_ollama&quot;,
  &quot;choices&quot;:[
    {
      &quot;index&quot;:0,
      &quot;message&quot;:{
        &quot;role&quot;:&quot;assistant&quot;,
        &quot;content&quot;:&quot;您好！很高兴能与您保持联系。希望在未来的日子里能够共同进步、共事、共患难，一起克服任何挑战，享受生活乐趣。如果还有其他需求或问题，请随时告诉我哦！&quot;
      },
      &quot;finish_reason&quot;:&quot;stop&quot;
    }
  ],
  &quot;usage&quot;:{
    &quot;prompt_tokens&quot;:40,
    &quot;completion_tokens&quot;:50,
    &quot;total_tokens&quot;:90
  }
}
</code></pre>
<p>从这里可以看出，基于大模型的应用可以通过调整真实的用户聊天的上下文来影响最终的回答。有时候可以改进体验，有时候也可能被用于构建信息茧房。</p>
<h2>2.5 Go语言访问REST服务</h2>
<p>现在用Go语言连接REST服务。首先构造请求数据：</p>
<pre><code class="language-go">package main

import (
	&quot;encoding/json&quot;
	&quot;log&quot;
)

func main() {
	// 构造请求体
	requestData := map[string]any{
		&quot;model&quot;: &quot;deepseek-r1:1.5b&quot;,
		&quot;messages&quot;: []map[string]any{
			{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，今天怎么样？&quot;},
			{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;你好呀！我今天很好，谢谢！&quot;},
			{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你做了什么？&quot;},
			{&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;我今天一直在和你聊天！&quot;},
			{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;那我们继续聊吧！&quot;},
		},
		&quot;temperature&quot;: 0.7,
		&quot;max_tokens&quot;:  150,
	}

	// 将请求体序列化为JSON
	jsonData, err := json.Marshal(requestData)
	if err != nil {
		log.Fatalf(&quot;无法序列化请求数据: %v&quot;, err)
	}

	...
}
</code></pre>
<p>然后以POST方式发出请求并读取响应数据：</p>
<pre><code class="language-go">package main

import (
	&quot;encoding/json&quot;
	&quot;io&quot;
	&quot;log&quot;
	&quot;net/http&quot;
)

func main() {
	...
	// 创建 POST 请求
	url := &quot;http://localhost:11434/v1/chat/completions&quot;
	req, err := http.NewRequest(&quot;POST&quot;, url, bytes.NewBuffer(jsonData))
	if err != nil {
		log.Fatalf(&quot;无法创建请求: %v&quot;, err)
	}

	// 设置请求头
	req.Header.Set(&quot;Content-Type&quot;, &quot;application/json&quot;)

	// 发送请求
	client := &amp;http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		log.Fatalf(&quot;请求失败: %v&quot;, err)
	}
	defer resp.Body.Close()

	// 读取响应数据
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Fatalf(&quot;读取响应失败: %v&quot;, err)
	}
	...
}
</code></pre>
<p>最后是解码收到的回答：</p>
<pre><code class="language-go">func main() {
	...
	// 解析响应数据
	var result struct {
		Choices []struct {
			Message struct {
				Role    string `json:&quot;role&quot;`
				Content string `json:&quot;content&quot;`
			} `json:&quot;message&quot;`
		} `json:&quot;choices&quot;`
	}
	if err = json.Unmarshal(body, &amp;result); err != nil {
		log.Fatalf(&quot;解码响应失败: %v&quot;, err)
	}

	fmt.Println(result.Choices[0].Message.Content)
}
</code></pre>
<p>以上的代码虽然比较简陋，但是和其他SDK的工作原理类似，最底层都是通过POST调用大模型服务获取结果。</p>


                        

                        

                        
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../ch1-hello-llm/readme.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                        
                            <!-- ../ch3-llm-chat/readme.html -->
                            <a rel="next" href="../ch3-llm-chat/readme.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../ch1-hello-llm/readme.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                
                    <a rel="next" href="../ch3-llm-chat/readme.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../static/wabook/mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../static/wabook/book.js" type="text/javascript" charset="utf-8"></script>
        
        <script type="text/javascript" charset="utf-8">
            var pagePath = "ch2-rest-api/readme.md"
        </script>

        <!-- Custom JS scripts -->
        

    </body>
</html>
